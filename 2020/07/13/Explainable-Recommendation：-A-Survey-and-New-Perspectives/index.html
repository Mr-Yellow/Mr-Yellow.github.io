<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Explainable Recommendation： A Survey and New Perspectives | YoYoghurt's Blog</title><meta name="description" content="Explainable Recommendation： A Survey and New PerspectivesAbstract可解释的推荐模型（explainable recommendation）不仅仅产生高质量的推荐，它还提供了为何产生这种推荐的原因。 可解释模型解决的问题是：为什么算法会把这个对象推荐出来？ 它面对的人群是用户或者系统的设计者，可以解决这两类人的疑惑 可解释模型可以用于改"><meta name="keywords" content="Explainable_Recommendation, paper_reading"><meta name="author" content="YoYoghurt"><meta name="copyright" content="YoYoghurt"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="https://cdn.jsdelivr.net/gh/Mr-Yellow/ImgHosting/Blog-Pic20200705171347.png"><link rel="canonical" href="http://yoursite.com/2020/07/13/Explainable-Recommendation%EF%BC%9A-A-Survey-and-New-Perspectives/"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//fonts.googleapis.com" crossorigin="crossorigin"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta property="og:type" content="article"><meta property="og:title" content="Explainable Recommendation： A Survey and New Perspectives"><meta property="og:url" content="http://yoursite.com/2020/07/13/Explainable-Recommendation%EF%BC%9A-A-Survey-and-New-Perspectives/"><meta property="og:site_name" content="YoYoghurt's Blog"><meta property="og:description" content="Explainable Recommendation： A Survey and New PerspectivesAbstract可解释的推荐模型（explainable recommendation）不仅仅产生高质量的推荐，它还提供了为何产生这种推荐的原因。 可解释模型解决的问题是：为什么算法会把这个对象推荐出来？ 它面对的人群是用户或者系统的设计者，可以解决这两类人的疑惑 可解释模型可以用于改"><meta property="og:image" content="https://cdn.jsdelivr.net/gh/Mr-Yellow/ImgHosting/Blog-Pic20200705174112.jpg"><meta property="article:published_time" content="2020-07-13T15:01:55.000Z"><meta property="article:modified_time" content="2020-07-13T15:05:35.652Z"><meta name="twitter:card" content="summary"><script>var activateDarkMode = function () {
  document.documentElement.setAttribute('data-theme', 'dark')
  if (document.querySelector('meta[name="theme-color"]') !== null) {
    document.querySelector('meta[name="theme-color"]').setAttribute('content', '#000')
  }
}
var activateLightMode = function () {
  document.documentElement.setAttribute('data-theme', 'light')
  if (document.querySelector('meta[name="theme-color"]') !== null) {
    document.querySelector('meta[name="theme-color"]').setAttribute('content', '#fff')
  }
}

var getCookies = function (name) {
  const value = `; ${document.cookie}`
  const parts = value.split(`; ${name}=`)
  if (parts.length === 2) return parts.pop().split(';').shift()
}

var autoChangeMode = 'false'
var t = getCookies('theme')
if (autoChangeMode === '1') {
  var isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
  var isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
  var isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
  var hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

  if (t === undefined) {
    if (isLightMode) activateLightMode()
    else if (isDarkMode) activateDarkMode()
    else if (isNotSpecified || hasNoSupport) {
      console.log('You specified no preference for a color scheme or your browser does not support it. I Schedule dark mode during night time.')
      var now = new Date()
      var hour = now.getHours()
      var isNight = hour <= 6 || hour >= 18
      isNight ? activateDarkMode() : activateLightMode()
    }
    window.matchMedia('(prefers-color-scheme: dark)').addListener(function (e) {
      if (Cookies.get('theme') === undefined) {
        e.matches ? activateDarkMode() : activateLightMode()
      }
    })
  } else if (t === 'light') activateLightMode()
  else activateDarkMode()
} else if (autoChangeMode === '2') {
  now = new Date()
  hour = now.getHours()
  isNight = hour <= 6 || hour >= 18
  if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
  else if (t === 'light') activateLightMode()
  else activateDarkMode()
} else {
  if (t === 'dark') activateDarkMode()
  else if (t === 'light') activateLightMode()
}</script><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css"><link rel="next" title="Hexo搭建过程" href="http://yoursite.com/2020/07/01/construct-the-blog/"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css"><script src="https://cdn.jsdelivr.net/npm/gitalk@latest/dist/gitalk.min.js"></script><script src="https://cdn.jsdelivr.net/npm/blueimp-md5/js/md5.min.js"></script><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web&amp;display=swap"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容:${query}"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  bookmark: {
    message_prev: '按',
    message_next: '键将本页加入书签'
  },
  runtime_unit: '天',
  runtime: true,
  copyright: undefined,
  ClickShowText: undefined,
  medium_zoom: false,
  fancybox: true,
  Snackbar: {"bookmark":{"message_prev":"按","message_next":"键将本页加入书签"},"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#121212","position":"bottom-left"},
  justifiedGallery: {
    js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
    css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
  },
  baiduPush: false,
  highlightCopy: true,
  highlightLang: true,
  isPhotoFigcaption: false,
  islazyload: true,
  isanchor: true    
}</script><script>var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isSidebar: true
  }</script><noscript><style>
#nav {
  opacity: 1
}
.justified-gallery img{
  opacity: 1
}
</style></noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome/css/font-awesome.min.css"><script src="https://cdn.jsdelivr.net/npm/jquery/dist/jquery.min.js"></script><script src="/live2d-widget/autoload.js"></script><meta name="generator" content="Hexo 4.2.1"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="https://cdn.jsdelivr.net/gh/Mr-Yellow/ImgHosting/Blog-Pic20200705172540.jpg" onerror="onerror=null;src='https://cdn.jsdelivr.net/gh/Mr-Yellow/ImgHosting/Blog-Pic20200705172719.gif'" alt="avatar"/></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">文章</div><div class="length_num">3</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">标签</div><div class="length_num">4</div></a></div></div><div class="mobile_data_item is-center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">分类</div><div class="length_num">2</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间线</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page"><i class="fa-fw fas fa-list"></i><span> 娱乐</span><i class="fas fa-chevron-down menus-expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li><li><a class="site-page" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 影视</span></a></li><li><a class="site-page" href="/books/"><i class="fa-fw fas fa-book"></i><span> 阅读</span></a></li><li><a class="site-page" href="/Gallery/"><i class="fa-fw fas fa-images"></i><span> 相册</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page"><i class="fa-fw fas fa-question"></i><span> 关于</span><i class="fas fa-chevron-down menus-expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/aboutme/"><i class="fa-fw fas fa-heart"></i><span> 我？</span></a></li></ul></div></div></div></div><i class="fas fa-arrow-right" id="toggle-sidebar"></i><div id="sidebar"><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Explainable-Recommendation：-A-Survey-and-New-Perspectives"><span class="toc-number">1.</span> <span class="toc-text">Explainable Recommendation： A Survey and New Perspectives</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Abstract"><span class="toc-number">1.1.</span> <span class="toc-text">Abstract</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Introduction"><span class="toc-number">1.2.</span> <span class="toc-text">Introduction</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Explainable-Recommendation"><span class="toc-number">1.2.1.</span> <span class="toc-text">Explainable Recommendation</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Historical-Overview"><span class="toc-number">1.2.2.</span> <span class="toc-text">Historical Overview</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Classification-of-the-methods"><span class="toc-number">1.2.3.</span> <span class="toc-text">Classification of the methods</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Explainability-and-Effectiveness"><span class="toc-number">1.2.4.</span> <span class="toc-text">Explainability and Effectiveness</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#How-to-Read-the-Survey"><span class="toc-number">1.2.5.</span> <span class="toc-text">How to Read the Survey</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Information-Source-for-Explanations"><span class="toc-number">1.3.</span> <span class="toc-text">Information Source for Explanations</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#用相关用户或者对象进行解释"><span class="toc-number">1.3.1.</span> <span class="toc-text">用相关用户或者对象进行解释</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#基于特征的解释"><span class="toc-number">1.3.2.</span> <span class="toc-text">基于特征的解释</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#基于观点的解释"><span class="toc-number">1.3.3.</span> <span class="toc-text">基于观点的解释</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#视觉解释"><span class="toc-number">1.3.4.</span> <span class="toc-text">视觉解释</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#社交解释"><span class="toc-number">1.3.5.</span> <span class="toc-text">社交解释</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#总结"><span class="toc-number">1.3.6.</span> <span class="toc-text">总结</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Explainable-Recommendation-Models"><span class="toc-number">1.4.</span> <span class="toc-text">Explainable Recommendation Models</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Overview-of-Machine-Learning-for-Recommendation"><span class="toc-number">1.4.1.</span> <span class="toc-text">Overview of Machine Learning for Recommendation</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Factorization-Models-for-Explainable-Recommendation"><span class="toc-number">1.4.2.</span> <span class="toc-text">Factorization Models for Explainable Recommendation</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Topic-Modeling-for-Explainable-Recommendation"><span class="toc-number">1.4.3.</span> <span class="toc-text">Topic Modeling for Explainable Recommendation</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Graph-based-Models-for-Explainbale-Recommendation"><span class="toc-number">1.4.4.</span> <span class="toc-text">Graph-based Models for Explainbale Recommendation</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Deep-Learning-for-Explainable-Recommendation"><span class="toc-number">1.4.5.</span> <span class="toc-text">Deep Learning for Explainable Recommendation</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Knowledge-Graph-based-Explainable-Recommendation"><span class="toc-number">1.4.6.</span> <span class="toc-text">Knowledge Graph-based Explainable Recommendation</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Rule-Mining-for-Explainable-Recommendation"><span class="toc-number">1.4.7.</span> <span class="toc-text">Rule Mining for Explainable Recommendation</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Model-Agnostic-and-Post-Hoc-Explainable-Recommendation"><span class="toc-number">1.4.8.</span> <span class="toc-text">Model Agnostic and Post Hoc Explainable Recommendation</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Summary"><span class="toc-number">1.4.9.</span> <span class="toc-text">Summary</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Evaluation-of-Explainable-Recommendation"><span class="toc-number">1.5.</span> <span class="toc-text">Evaluation of Explainable Recommendation</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#User-Study"><span class="toc-number">1.5.1.</span> <span class="toc-text">User Study</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Online-Evaluation"><span class="toc-number">1.5.2.</span> <span class="toc-text">Online Evaluation</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Offline-Evaluation"><span class="toc-number">1.5.3.</span> <span class="toc-text">Offline Evaluation</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Qualitative-Evaluation-by-Case-Study"><span class="toc-number">1.5.4.</span> <span class="toc-text">Qualitative Evaluation by Case Study</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Explainable-Recommendation-in-Diﬀerent-Applications"><span class="toc-number">1.6.</span> <span class="toc-text">Explainable Recommendation in Diﬀerent Applications</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Explainable-E-commerce-Recommendation"><span class="toc-number">1.6.1.</span> <span class="toc-text">Explainable E-commerce Recommendation</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Explainable-Point-of-Interest-Recommendation"><span class="toc-number">1.6.2.</span> <span class="toc-text">Explainable Point-of-Interest Recommendation</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Explainable-Social-Recommendation"><span class="toc-number">1.6.3.</span> <span class="toc-text">Explainable Social Recommendation</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Explainable-Multimedia-Recommendation"><span class="toc-number">1.6.4.</span> <span class="toc-text">Explainable Multimedia Recommendation</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Other-Explainable-Recommendation-Applications"><span class="toc-number">1.6.5.</span> <span class="toc-text">Other Explainable Recommendation Applications</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Summary-1"><span class="toc-number">1.6.6.</span> <span class="toc-text">Summary</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Open-Directions-and-New-Perspectives"><span class="toc-number">1.7.</span> <span class="toc-text">Open Directions and New Perspectives</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Explainable-Deep-Learning-for-Recommendation"><span class="toc-number">1.7.1.</span> <span class="toc-text">Explainable Deep Learning for Recommendation</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Konwledge-enhanced-Explainable-Recommendation"><span class="toc-number">1.7.2.</span> <span class="toc-text">Konwledge-enhanced Explainable Recommendation</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Multi-Modality-and-Heterogenous-Information-Modeling"><span class="toc-number">1.7.3.</span> <span class="toc-text">Multi-Modality and Heterogenous Information Modeling</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Context-aware-Explanations"><span class="toc-number">1.7.4.</span> <span class="toc-text">Context-aware Explanations</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Aggregation-of-Different-Explanations"><span class="toc-number">1.7.5.</span> <span class="toc-text">Aggregation of Different Explanations</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Explainable-Recommendation-as-Reasoning"><span class="toc-number">1.7.6.</span> <span class="toc-text">Explainable Recommendation as Reasoning</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#NLP-and-Explainable-Recommendation"><span class="toc-number">1.7.7.</span> <span class="toc-text">NLP and Explainable Recommendation</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Answering-the-Why-in-Conversations"><span class="toc-number">1.7.8.</span> <span class="toc-text">Answering the Why in Conversations</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Evaluation-of-Explainable-Recommendations"><span class="toc-number">1.7.9.</span> <span class="toc-text">Evaluation of Explainable Recommendations</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#User-Behavior-Perspectives"><span class="toc-number">1.7.10.</span> <span class="toc-text">User Behavior Perspectives</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Explanation-for-Broader-Impects"><span class="toc-number">1.7.11.</span> <span class="toc-text">Explanation for Broader Impects</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Cognitive-Science-Foundations"><span class="toc-number">1.7.12.</span> <span class="toc-text">Cognitive Science Foundations</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Conclusion"><span class="toc-number">1.8.</span> <span class="toc-text">Conclusion</span></a></li></ol></li></ol></div></div></div><div id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(https://cdn.jsdelivr.net/gh/Mr-Yellow/ImgHosting/Blog-Pic20200705174112.jpg)"><nav id="nav"><span class="pull-left" id="blog_name"><a class="blog_title" id="site-name" href="/">YoYoghurt's Blog</a></span><span class="pull-right menus"><div id="search_button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间线</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page"><i class="fa-fw fas fa-list"></i><span> 娱乐</span><i class="fas fa-chevron-down menus-expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li><li><a class="site-page" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 影视</span></a></li><li><a class="site-page" href="/books/"><i class="fa-fw fas fa-book"></i><span> 阅读</span></a></li><li><a class="site-page" href="/Gallery/"><i class="fa-fw fas fa-images"></i><span> 相册</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page"><i class="fa-fw fas fa-question"></i><span> 关于</span><i class="fas fa-chevron-down menus-expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/aboutme/"><i class="fa-fw fas fa-heart"></i><span> 我？</span></a></li></ul></div></div><span class="toggle-menu close"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></span></span></nav><div id="post-info"><div id="post-title"><div class="posttitle">Explainable Recommendation： A Survey and New Perspectives</div></div><div id="post-meta"><div class="meta-firstline"><time class="post-meta__date"><span class="post-meta__date-created" title="发表于 2020-07-13 23:01:55"><i class="far fa-calendar-alt fa-fw"></i> 发表于 2020-07-13</span><span class="post-meta__separator">|</span><span class="post-meta__date-updated" title="更新于 2020-07-13 23:05:35"><i class="fas fa-history fa-fw"></i> 更新于 2020-07-13</span></time><span class="post-meta__categories"><span class="post-meta__separator">|</span><i class="fas fa-inbox fa-fw post-meta__icon"></i><a class="post-meta__categories" href="/categories/Paper/">Paper</a></span></div><div class="meta-secondline"> <span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta__icon"></i><span>字数总计:</span><span class="word-count">9.9k</span><span class="post-meta__separator">|</span><i class="far fa-clock fa-fw post-meta__icon"></i><span>阅读时长: 30 分钟</span></span></div><div class="meta-thirdline"><span class="post-meta-pv-cv"><span class="post-meta__separator">|</span><i class="far fa-eye fa-fw post-meta__icon"></i><span>阅读量:</span><span id="busuanzi_value_page_pv"></span></span><span class="post-meta-commentcount"></span></div></div></div></header><main class="layout_post" id="content-inner"><article id="post"><div class="post-content" id="article-container"><h1 id="Explainable-Recommendation：-A-Survey-and-New-Perspectives"><a href="#Explainable-Recommendation：-A-Survey-and-New-Perspectives" class="headerlink" title="Explainable Recommendation： A Survey and New Perspectives"></a>Explainable Recommendation： A Survey and New Perspectives</h1><h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>可解释的推荐模型（explainable recommendation）不仅仅产生高质量的推荐，它还提供了为何产生这种推荐的原因。</p>
<p>可解释模型解决的问题是：为什么算法会把这个对象推荐出来？</p>
<p>它面对的人群是用户或者系统的设计者，可以解决这两类人的疑惑</p>
<p>可解释模型可以用于改进推荐系统的透明度、可信度、满意度、效果。</p>
<p>本文对可解释的推荐进行了一个综合的回顾。本文将推荐问题分类为what、when、who、where、why，并且说明可解释的推荐在推荐系统研究中的位置。</p>
<p>本文从三个方面研究可解释的推荐系统：</p>
<ul>
<li>按时间顺序说明关于可解释推荐相关的研究</li>
<li>提供两个维度用于分类可解释的推荐研究：<pre><code>- 解释的信息源
    - 产生可解释推荐的算法机制</code></pre></li>
<li>总结如何将可解释的推荐应用到不同的推荐任务上，比如商品推荐、社交推荐、POI（point of interest）推荐</li>
</ul>
<p>本文还对AI和ML领域的研究从可解释的角度进行讨论。最后，本文讨论了一些可以提升可解释推荐领域的研究方向。</p>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><h3 id="Explainable-Recommendation"><a href="#Explainable-Recommendation" class="headerlink" title="Explainable Recommendation"></a>Explainable Recommendation</h3><p>可解释的推荐指的是解决了为什么问题的个性化推荐算法</p>
<p>个性化的推荐研究可以被分类到5W问题中：</p>
<ul>
<li>时间感知的推荐（time-aware）-&gt;when</li>
<li>基于位置的推荐（location-based）-&gt;where</li>
<li>社交推荐-&gt;who</li>
<li>应用感知的推荐（application-aware）-&gt;what</li>
<li>可解释的推荐-&gt;why</li>
</ul>
<p>可解释的模型可以分为：模型内嵌（model-intrinsic）、模型不相关（model-agnostic）[^Lipton,2018,the mythos][^Molnar,2019,interpretable]</p>
<ul>
<li>model-intrinsic：推荐模型的决策机制是透明的，可以知道其如何形成决策，自然就知道为什么会这样决策[^zhang,2014,explicit]</li>
<li>model-agnostic：决策过程可以不透明，使用一个用于生成解释的模型，在做出决策之后为其生成解释，这种方法也叫做因果颠倒法（post-hoc）[^wang,2018,a reinforcement learning][^Peak,2018,explanation mining]</li>
</ul>
<p>这两种方法是建立在人类的认知心理学基础上的：有时我们通过思考和推理自然地产生应该做的决定；有时我们先做决定，然后为这个决定找理由。</p>
<p>可解释推荐不仅仅要建立一个可解释的模型，同时还要建立一种将解释分发给用户的方法</p>
<h3 id="Historical-Overview"><a href="#Historical-Overview" class="headerlink" title="Historical Overview"></a>Historical Overview</h3><p>早期的个性化推荐系统主要是基于内容或者协同过滤CF，进行推荐[^Ricci,2011,Introduction to recommender]。</p>
<ul>
<li>基于内容（content-based）的推荐系统用各种内容信息，比如价格、品牌、颜色等来建模用户和项目[^Balabanovic,1997,Fab: content-based][^Pazzani,2007,content-based recommendation]，内容信息对于用户来说本来就很好理解，直接将被推荐的项目的这些信息告诉用户，就可以起到解释的作用。对于基于内容的推荐的解释的研究可以看[^Ferwerda,2012,Explaining Content-based]。收集用于建模的信息是很耗费时间的，这是该方法的弊端。</li>
<li>基于协同过滤（collaborative filtering，CF）的方法使用群体智能来解决收集信息耗时的问题[^Ekstrand,2011,collaborative filtering]。协同过滤推荐方法又可以分为两个方面：<pre><code>- 基于用户（user-based）的CF[^Resnick,1994,GroupLens]，这种方法用一个向量表示用户对于一个新闻的评级，对于那些没有评级的用户，使用其他用户的评级的加权平均来预测。（它基于的事实是，一个用户可能用到的东西是和他兴趣相同的其他用户用过的东西）
- 基于项目（item-based）的CF[^Sarwar,2001,Item-based]，这种方法将项目的评分作为一个向量，使用相似的项目的加权平均来预测缺失的评分。亚马逊的商品推荐就属于基于项目的协同过滤[^Linden,2003,Amazon.com]（它基于的事实是，一个用户未来可能用到的东西是和他曾经用过的东西类似的东西）</code></pre></li>
</ul>
<p>协同过滤在可解释性上不像基于内容的方法这么直观，[^Herlocker,2000; Konstan,2000; Sinha,2002]这些文章研究了如何解释协同过滤方法。</p>
<p>后来，协同过滤方法和LFM（Latent Factor Model）结合起来，尤其是LFM中的MF（Matrix Factorization）取得了很好的效果[^Koren,2008; Koren,2009]。但是，LFM中的Latent Factor也没有直观的含义，可解释性弱。</p>
<p>可解释推荐问题这个名词最早是[^zhang,2014,Explicit factor models for explainbale recommendation]提出的，它用的模型是EFM。</p>
<p>深度学习模型是不是能提高推荐推荐系统的能力目前是存疑的[^Dacrema,2019,Are we really making]。</p>
<p>可解释问题在1980年就受到关注。Clancy说明了要对一个预测做出解释需要的知识比做出这个预测要多得多[^Clancy,1982,the epistemology]，最近可解释性问题又受到重视，人们希望解决广泛的领域里的AI可解释性问题，比如视觉的可解释性、NLP、自动驾驶的可解释性[^Gunning,2017,Explainable artificial]。</p>
<h3 id="Classification-of-the-methods"><a href="#Classification-of-the-methods" class="headerlink" title="Classification of the methods"></a>Classification of the methods</h3><p>为了分类现存的可解释模型，本文使用两个维度来区别分类：</p>
<ul>
<li>解释的展示方式（是用一句话表示解释？一张图表示解释？），这是从人机交互（HCI）方式的角度分类</li>
<li>产生解释的算法（近邻模型？矩阵分解？话题模型？图模型？深度学习？知识推理？关系规则挖掘？），这是从算法角度分类</li>
</ul>
<p>使用这两种方法进行分类模型，可以在表1.1中看到分类结果</p>
<h3 id="Explainability-and-Effectiveness"><a href="#Explainability-and-Effectiveness" class="headerlink" title="Explainability and Effectiveness"></a>Explainability and Effectiveness</h3><p>以往认为模型的有效性和可解释性是冲突的[^Ricci,2011,Introduction]。最近有证据表明这两个可能不冲突[^Biligic,2004,Explanation for recommender][^zhang,2014,Explicit]，比如深度表示学习既可以做到有效又可以做到可解释。</p>
<h3 id="How-to-Read-the-Survey"><a href="#How-to-Read-the-Survey" class="headerlink" title="How to Read the Survey"></a>How to Read the Survey</h3><p>进入这个领域需要有两个方面的知识：</p>
<p>1、推荐系统领域的知识</p>
<ul>
<li>Pazzani and Billsus，2007</li>
<li>Ekstrand et al., 2011</li>
<li>Shani and Gunawardana, 2011</li>
</ul>
<p>2、可解释性领域的知识</p>
<ul>
<li>Tintarev and Masthoff, 2007a</li>
<li>(Lipton, 2018; Molnar, 2019</li>
<li>Gunning, 2017; Samek et al., 2017</li>
</ul>
<h2 id="Information-Source-for-Explanations"><a href="#Information-Source-for-Explanations" class="headerlink" title="Information Source for Explanations"></a>Information Source for Explanations</h2><p>推荐的解释可以产生于不同的信息源并且用不同的方式进行表现[^Tintarev,2015,Explaining recommendations]，同一个推荐可以有不同的解释。</p>
<p>一些论文及其解释的表示方式：</p>
<ul>
<li>zhang2014a：用句子解释</li>
<li>Wu2015 和 zhang2015 和 kadry2014：用词云解释</li>
<li>chen2019b：用视觉图像解释</li>
<li>Sharma2013 和 Quijano2017：用社交关系解释</li>
<li>Herlocker2000 和 Bilgic2005 和 Tintarev2007b 和 McSherry2005：使用统计直方图或者饼图解释</li>
<li>Du2019：提供视觉分析方法</li>
</ul>
<h3 id="用相关用户或者对象进行解释"><a href="#用相关用户或者对象进行解释" class="headerlink" title="用相关用户或者对象进行解释"></a>用相关用户或者对象进行解释</h3><p>这个部分主要说明基于用户和基于项目的协同过滤的可解释性问题，因为采用这两种方法的推荐一般使用相关的用户或者对象进行解释。</p>
<ul>
<li><p>基于用户的协同过滤：找到和目标用户相似的用户，推荐他们喜欢的项目，该方法的解释性就是，因为目标用户和某一个群体用户相似，而且这个群体用户都对该项目的评价很好。Resnick1994讲了基于用户的协同过滤方法，Herlocker2000使用相似用户的评价的直方图或者相似用户的评价进行解释，如下图：</p>
<p><img src= "https://cdn.jsdelivr.net/gh/Mr-Yellow/ImgHosting/Blog-Pic20200705173220.gif" data-src="https://cdn.jsdelivr.net/gh/Mr-Yellow/ImgHosting/Blog-Pic20200713225429.jpg" alt></p>
</li>
<li><p>基于项目的协同过滤：可以通过告诉用户被推荐的项目和他以前使用其他项目很相似达到解释的目的。Sarwar2001是关于使用基于项目的协同过滤。</p>
</li>
</ul>
<p>Tintarev2007开发了一个原型，用于研究添加解释到推荐系统的结果，他认为添加解释会带来七个好处：transpancy、scrutability、trustworthiness、effectiveness、persuasiveness、efficiency、satification，并且经过用户研究，确实会带来这样的好处。</p>
<p>一般来说，基于项目的解释比基于用户的解释可信，因为用户之前使用过相似的产品，而且，基于用户的解释可能会泄露用户的隐私，为了结局隐私问题，现在使用基于社交的解释替代基于用户的解释，[^Ren2017]和[^Tsai2018]就是使用这样的社交解释。</p>
<h3 id="基于特征的解释"><a href="#基于特征的解释" class="headerlink" title="基于特征的解释"></a>基于特征的解释</h3><p>基于特征的解释和基于内容的推荐方法有密切关系，基于内容的推荐中，系统匹配用户肖像和候选项目的内容特征进行推荐。Pazzani2007、Ferwerda2012、Cramer2008都是基于内容的推荐。</p>
<p>基于特征的解释可以有多种表现形式：</p>
<ul>
<li>标签解释方法：用项目的标签以及你对该标签的喜好程度进行解释。Vig2009就是一个电影标签进行推荐的例子。</li>
<li>雷达图解释法：用用户对各个方面的偏好和项目各个方面的能力的匹配程度进行推荐。Hou2018用雷达图解释。</li>
<li>用户人口统计学信息解释法：用用户的年龄、性别、住址信息进行推荐和解释，常常和社交媒体结合起来。Pazzani1999、Zhao2014、Zhao2016都是用人口统计学信息的方法。</li>
</ul>
<h3 id="基于观点的解释"><a href="#基于观点的解释" class="headerlink" title="基于观点的解释"></a>基于观点的解释</h3><p>现在人们可以对于项目进行评论，发表自己的观点。从这些观点中我们可以发现用户对一些方面的偏好，这些偏好可以用于推荐，也可以用于解释。McAuley2013、Zheng2017、zhang2014a、Li2017都是用这些观点进行推荐和解释。</p>
<p>基于观点的解释可以分为两种方法：</p>
<ul>
<li><p>方面级别的（aspects-level）：方面级别的解释和基于特征的解释很像，区别是，方面信息是从用户的评论中抽取出来的，特征则是人为规定有哪些特征。抽取方面信息和情感分析有关，Hu2004、Lu2011、Liu2012、Zhang2014b都是关于情感分析的。</p>
<p>尤其是Zhang2014b，这篇文章开发了一个toolkit叫Sentires，用于抽取“方面-观点-情感”三元组，在这个工具基础上，Zhang2014a、Wu2015、Ren2017、Wang2018b都是用于解释推荐的。</p>
</li>
<li><p>句子级别的：这个方法可以分为基于模板的句子和基于产生的句子</p>
<ul>
<li>模板句子法：定义一些句子的模板，比如“你对某某特征比较感兴趣，因此，你可能会喜欢某某商品”，特征是个性化得到的，用于后期填入。Zhang2014a、Wang2018b、Tao2019a、Gao2019都是模板方法。</li>
<li>自然语言产生技术：一般是使用LSTM等语言生成模型在评论数据上训练得到的。Costa2018、Chang2016、Li2017、Lu2018b、Chen2019a、Ni2019这些是使用语言模型的方法。</li>
</ul>
</li>
</ul>
<h3 id="视觉解释"><a href="#视觉解释" class="headerlink" title="视觉解释"></a>视觉解释</h3><p>视觉解释就是在图片中标明哪个部分是推荐给用户的的原因，这个方法通常要将用户的评论和图片的区域联系起来。Lin2019、Chen2019b都是有关视觉图片解释的。</p>
<h3 id="社交解释"><a href="#社交解释" class="headerlink" title="社交解释"></a>社交解释</h3><p>用和目标用户相似的用户解释一个推荐，可能并不是那么容易被理解，如果将用来解释的用户换成目标用户的朋友，那么就比较有说服力。</p>
<p>Facebook提供共同朋友作为推荐一个新的朋友的依据（Papadimitriou2012）；音乐推荐可以提供有多少朋友喜欢这个音乐（Sharma2013）；在商品推荐中指出和其有社交关系的人喜欢什么商品（Park2018）；将社交解释用于群推荐，提高接受程度和满意度（Quijano2017）；为了找到一个最有说服力的用户集合，采用两阶段排名算法找到这个集合（Wang2014）</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>推荐解释的类型可以划分为六类：</p>
<ul>
<li>基于用户和项目的解释：和协同过滤有关</li>
<li>基于特征的解释：和基于内容的推荐有关</li>
<li>基于观点的解释：从用户评论中抽取观点，和情感分析有关</li>
<li>文本句子的解释：用模板或者自然语言处理方法处理文本句子</li>
<li>视觉解释：整张图片或者图片的一部分</li>
<li>社交解释：基于用户的社交关系的解释</li>
</ul>
<p>1-3类和推荐算法有关，4-6和如何展示解释有关。</p>
<h2 id="Explainable-Recommendation-Models"><a href="#Explainable-Recommendation-Models" class="headerlink" title="Explainable Recommendation Models"></a>Explainable Recommendation Models</h2><p>推荐的可解释性包含推荐方法的可解释性或者推荐结果的可解释性。推荐方法的可解释性就是模型生成推荐的过程是透明的，因此，形成的结果也就是可解释的。结果的可解释性是将模型视为一个黑箱，使用另外一个模型生成解释。</p>
<h3 id="Overview-of-Machine-Learning-for-Recommendation"><a href="#Overview-of-Machine-Learning-for-Recommendation" class="headerlink" title="Overview of Machine Learning for Recommendation"></a>Overview of Machine Learning for Recommendation</h3><p>一个传统的用于推荐的ML模型是LFM，它基于MF（矩阵分解）。矩阵分解的方法可以是SVD、NMF、MMMF、PMF、LMF。矩阵分解方法是一种逐点预测的方法。</p>
<p>成对学习用于学习正确的项目排名，基于隐含的反馈。Rendle2009提出BPR，用于学习购买的物品和未购买的项目的相对排名；Rendle2010进一步扩展张量分解的想法到模型成对交互；Shi2010采用列表学习为协同过滤排名。</p>
<p>使用深度学习的推荐方法有：</p>
<p>Cheng2016的Wide and Deep网络；Covington2016将DNN用于youtube推荐系统；Zheng2017的文本卷积网络；Chen2019b的图像卷积；Hidasi2016的基于用户行为的RNN；Wu2016的自动编码器；Chen2018c的记忆网络。</p>
<p>神经网络模型是否真的有效是有争议的，Dacrema2019提出这个问题。Zhang2019认为只要可用于训练的数据足够多，深度模型就有效。</p>
<h3 id="Factorization-Models-for-Explainable-Recommendation"><a href="#Factorization-Models-for-Explainable-Recommendation" class="headerlink" title="Factorization Models for Explainable Recommendation"></a>Factorization Models for Explainable Recommendation</h3><p>采用矩阵分解的可解释推荐模型，使用低维的向量表示用户和项目，表示向量的每个维度代表一个特定的可以影响用户决定的因素，但是，我们并不能直观的知道这些因素的含义是什么，因此，利用这些进行解释是很困难的。</p>
<p>为了解决这个问题，zhang2014a提出EFM，这个方法的想法是，从用户对产品的评论中获得产品的特征，以及用户喜欢的特征，是否为用户推荐这个产品，就看两者的特征是不是匹配了，这个模型将特征和矩阵分解的维度进行对齐，这样推荐的过程就变得可解释了。如下图：</p>
<p><img src= "https://cdn.jsdelivr.net/gh/Mr-Yellow/ImgHosting/Blog-Pic20200705173220.gif" data-src="https://cdn.jsdelivr.net/gh/Mr-Yellow/ImgHosting/Blog-Pic20200713225523.jpg" alt></p>
<p>用户对某些特征的喜好是会随着时间改变的，为了适应这种改变，zhang2015b提出了能够动态建模用户特征的方法。</p>
<p>chen2016将EFM扩展到张量分解，这个模型从评论中抽取产品特征，构成用户-产品-特征的三维矩阵，在这个矩阵上执行成对学习，来预测用户对特征和产品的偏好，继而提供推荐。如下图：</p>
<p><img src= "https://cdn.jsdelivr.net/gh/Mr-Yellow/ImgHosting/Blog-Pic20200705173220.gif" data-src="https://cdn.jsdelivr.net/gh/Mr-Yellow/ImgHosting/Blog-Pic20200713225627.jpg" alt></p>
<p>Wang2018b利用张量上的多任务学习进行推荐，一个是推荐任务，一个是解释任务，这个算法分别计算用户在某个产品属性上的观点向量，再计算产品在某个属性上的观点向量，两者相乘，得到是否应该推荐这个产品，以及为何推荐它。如下图：</p>
<p><img src= "https://cdn.jsdelivr.net/gh/Mr-Yellow/ImgHosting/Blog-Pic20200705173220.gif" data-src="https://cdn.jsdelivr.net/gh/Mr-Yellow/ImgHosting/Blog-Pic20200713225642.jpg" alt></p>
<p>在不同的产品上，用户对于属性的偏好分布是不同的（比如，对于衣物和电脑这两种商品，用户关注的属性就是不一样的，对于衣物，用户比较关心外观，对于电脑，用户可能比较关注性能参数），但是之前的方法假设的都是用户在不同的产品上有相同的特征偏好分布。chen2018b提出AFM使用注意力机制调整用户注意力的分布，解决这个问题。</p>
<p>为了分析LFM模型中输入和输出的关系，cheng2019a采用影响分析方法，追溯每个预测到训练数据中，提供直观的邻居形式的解释。</p>
<p>从评论中抽取的特征也可以作为推荐的对象，Bauman2017提出的SULM，这个模型抽取特征以及用户在这些特征上的情感，它将特征和情感整合到矩阵分解模型中，用它回归未知评分的项目，最终提供不仅仅是项目的推荐，同时也是特征的推荐。比如，推荐一个餐厅的同时可以为你推荐就餐时间、菜品等等。Qiu2016和Hou2018也差不多。</p>
<p>为了获得更好的推荐和解释，可以在LFM模型中增加树形或者图结构数据，Tao2019a使用了因式分解树结构数据，用于解释，该树形结构中的路径就是对结果的一种解释。</p>
<p>产生相关用户或者相关项目的解释，现有如下方法：</p>
<ul>
<li>Abdollahi2016、2017提出EFM，它的解释方法是“很多和你相似的用户都购买它”，该模型添加一个解释正则项到矩阵分解的目标函数中，使得用户的潜在向量和项目的潜在向量在很多邻居用户都购买它时变得很相似。</li>
<li>Liu2019，提出一个可解释的概率因式分解模型，应用影响机制，评价用户历史数据的重要性，用最相关的用户和项目去解释。它将用户或者项目分为五组：有影响的用户、容易被影响的用户、独立的用户、流行的项目、长尾的项目，它产生的解释是“推荐该项目是因为一个有影响力的用户也在使用它”</li>
</ul>
<h3 id="Topic-Modeling-for-Explainable-Recommendation"><a href="#Topic-Modeling-for-Explainable-Recommendation" class="headerlink" title="Topic Modeling for Explainable Recommendation"></a>Topic Modeling for Explainable Recommendation</h3><p>话题模型是用于处理大量的文本类型的评论的，它的可解释性主要通过话题词云的形式展现。</p>
<p>McAuley2013提出HFT模型，它在LFM模型和LDA之间搭建了一座桥，它将隐藏向量的维度和LDA的维度联系起来，这样可以理解为何用户对目标项目如此评分，同时知道用户喜欢的最重要的话题。</p>
<p>Tan2016提出在同一个语义空间中建模项目和用户的偏好，之后使用LFM得到推荐，对于推荐有重要作用的话题词可以被当做解释。如下图：</p>
<p><img src= "https://cdn.jsdelivr.net/gh/Mr-Yellow/ImgHosting/Blog-Pic20200705173220.gif" data-src="https://cdn.jsdelivr.net/gh/Mr-Yellow/ImgHosting/Blog-Pic20200713225706.jpg" alt></p>
<p>cheng2019b采用多种形式的数据丰富话题模型，比如不仅仅考虑文本形式的评论，还考虑产品的图片，它可以从不同的角度学习用户的喜好和项目的特征，并且知道哪个方面的特征比较重要，把它作为推荐。</p>
<p>Wu2015提出FLAME，它学习每个用户在项目不同方面的偏好（比如某一家餐馆的位置、干净程度、服务等），通过协同过滤学习一个用户在新的项目各个方面上的评分，提供解释的时候就把那些方面用词云的形式表现出来（如果这个方面评分高的话，词云中的词就比较大）。如下图：</p>
<p><img src= "https://cdn.jsdelivr.net/gh/Mr-Yellow/ImgHosting/Blog-Pic20200705173220.gif" data-src="https://cdn.jsdelivr.net/gh/Mr-Yellow/ImgHosting/Blog-Pic20200713225725.jpg" alt></p>
<p>Zhao2015设计了一个可以整合情感、方面、区域的框架，用它来进行POI推荐，每个用户的话题方面的喜好决定了如何解释。</p>
<p>Ren2017提出sCVR，使用“viewpoint”进行解释，“viewpoint”是一个元组，由概念、话题、情感组成。</p>
<p><img src= "https://cdn.jsdelivr.net/gh/Mr-Yellow/ImgHosting/Blog-Pic20200705173220.gif" data-src="https://cdn.jsdelivr.net/gh/Mr-Yellow/ImgHosting/Blog-Pic20200713225743.jpg" alt></p>
<h3 id="Graph-based-Models-for-Explainbale-Recommendation"><a href="#Graph-based-Models-for-Explainbale-Recommendation" class="headerlink" title="Graph-based Models for Explainbale Recommendation"></a>Graph-based Models for Explainbale Recommendation</h3><p>很多的用户-用户关系、用户-项目关系可以被视为图结构数据，尤其是在社交网络场景，因此，可解释的推荐可以基于图学习方法生成。</p>
<p>He2015引入三部分图结构建模用户-项目-方面关系，其中，方面指的是从用户评论中抽取的项目的特征，该工作还使用TriRank为图的顶点排序，解释是使用排名最高的方面进行解释。</p>
<p><img src= "https://cdn.jsdelivr.net/gh/Mr-Yellow/ImgHosting/Blog-Pic20200705173220.gif" data-src="https://cdn.jsdelivr.net/gh/Mr-Yellow/ImgHosting/Blog-Pic20200713225757.jpg" alt></p>
<p>不使用外部的信息，比如方面信息，Heckel2017在用户的-项目二部图上执行聚合算法，每个聚类中的用户有相似的属性，它的解释是“项目a被推荐给用户x，是因为x曾经购买过b、c、d三种项目，而具有相同的购买历史的用户y、z也都购买了a”。如下图（图中颜色相同的是有相同购买历史的用户聚合）：</p>
<p><img src= "https://cdn.jsdelivr.net/gh/Mr-Yellow/ImgHosting/Blog-Pic20200705173220.gif" data-src="https://cdn.jsdelivr.net/gh/Mr-Yellow/ImgHosting/Blog-Pic20200713225809.jpg" alt></p>
<p>Wang2018c将基于嵌入的模型和基于树形的模型结合在一起，基于树形的模型具有良好的解释性，基于嵌入的模型泛化能力良好，可以用于没有见过的用户和项目。</p>
<p>Park2018提出UniWalk算法，这是基于图的可解释推荐算法，它将产品评分和社交网络结合，产生可解释的推荐。解释是使用和目标用户有相同偏好的朋友进行解释。</p>
<h3 id="Deep-Learning-for-Explainable-Recommendation"><a href="#Deep-Learning-for-Explainable-Recommendation" class="headerlink" title="Deep Learning for Explainable Recommendation"></a>Deep Learning for Explainable Recommendation</h3><p>Seo2017提出一个使用CNN建模用户偏好以及项目属性的模型，它使用的素材是评论文本，在解释的时候，它使用了局部和全局的注意力，当进行预测时，模型选择评论词汇，并且赋予不同注意力权重，模型可以知道评论的那个部分比较重要，这些部分可以用于解释。</p>
<p><img src= "https://cdn.jsdelivr.net/gh/Mr-Yellow/ImgHosting/Blog-Pic20200705173220.gif" data-src="https://cdn.jsdelivr.net/gh/Mr-Yellow/ImgHosting/Blog-Pic20200713225830.jpg" alt></p>
<p>Wu2019将用户和项目的交互以及评论信息整合到统一的框架中。Lu2018a使用MF方法到评分上，使用基于注意力的GRU到评论数据上。Lu2018b添加了一个评论鉴别器，基于对抗s2s学习，因此，生成器可以产生评论，这个评论可以用于解释。</p>
<p>Gao2019提出DEAML用于缓解推荐精确度和可解释性之间的冲突，基本的想法是构建一个基于可解释的深度层级架构，这个模型可以建模多层特征。</p>
<p>Ma2019a提出可以自动学习从数据中分离出来的特征，它能够让用户控制推荐的结果。</p>
<p>Costa2018提出一个基于字符级RNN的方法，用于自动产生自然语言的解释，选择不同的参数，模型可以产生不同的解释。如图：</p>
<p><img src= "https://cdn.jsdelivr.net/gh/Mr-Yellow/ImgHosting/Blog-Pic20200705173220.gif" data-src="https://cdn.jsdelivr.net/gh/Mr-Yellow/ImgHosting/Blog-Pic20200713225849.jpg" alt></p>
<p>Li2017提出一个更加综合的模型去产生小贴士，这些贴士是对长评的总结。</p>
<p>Chen2019a将自然语言方法和特征词方法整合在一块，提出话题敏感的生成模型，为特定的特征词生成解释，模型可以控制解释是对那个方面的解释。</p>
<p>Chen2019d提出编码-选择-解码的架构，用于推荐解释，它探索了推荐任务和解释任务之间的相关性，使用共同注意力多任务学习。</p>
<p>Chang2016提出一个基于人类用户和众包的自然语言产生方法，他们首先使用无监督学习方法抽取电影评论的话题，之后为话题产生自然语言解释，具体是作者为每个话题收集相关的评论，然后让众包工人综合评论生成解释，最后，通过他们的活动建模他们的偏好。</p>
<p>Chen2018a不是生成解释，而是从用户评论中选择一个合适的作为解释，作者引入注意力机制去学习评论的有效性。</p>
<p>Chen2019b提出了一个结合了视觉图像和评论文本的模型，它既可以在图片中强调感兴趣的区域，又可以为感兴趣的区域生成解释。</p>
<p>Chen2018c研究了基于记忆网络的序列推荐模型，它将用户历史中的项目作为记忆模块，在模块上使用注意力机制，进行预测后续的行为。</p>
<p>Chen2019c提出动态可解释推荐，基于时间注意的GRU。</p>
<p>Tao2019b提出Log2Intent，它用于建模用户行为。</p>
<p>Li2019开发了一个胶囊网络，它考虑项目-用户对作为逻辑单元，逻辑单元是从评论中发掘出来的。</p>
<p>深度学习模型有时候不能决定模型产生的解释是不是真的反映了真实的产生推荐的机制。Jain2019认为注意力模型没有提供有意义的解释；Wiegreffe2019认为之前的工作没有证明注意力机制对于解释的有效性。</p>
<h3 id="Knowledge-Graph-based-Explainable-Recommendation"><a href="#Knowledge-Graph-based-Explainable-Recommendation" class="headerlink" title="Knowledge Graph-based Explainable Recommendation"></a>Knowledge Graph-based Explainable Recommendation</h3><p>Catherine2017提出同时为项目和知识图谱中的实体排序的方法，使用的是个性化的PageRank，实体是作为解释用的。</p>
<p>Ai2018提出使用知识图谱嵌入作为可解释推荐，该工作使用用户-项目知识图谱，模型为每个用户和项目生成一个嵌入，推荐的是和用户之前购买的项目相似的项目，解释可以使用用户和推荐项目的最短路表示。如下图：</p>
<p><img src= "https://cdn.jsdelivr.net/gh/Mr-Yellow/ImgHosting/Blog-Pic20200705173220.gif" data-src="https://cdn.jsdelivr.net/gh/Mr-Yellow/ImgHosting/Blog-Pic20200713225902.jpg" alt></p>
<p>Wang2018a提出一个RippleNet，模拟水面的波纹的传播，用来传播用户的偏好，最终可以预测点击的概率，解释可以通过知识图谱中的路径表示。</p>
<p>Huang2018将RNN和KV-MN结合起来，用于序列推荐，RNN是用于捕捉用户关于项目的偏好，记忆网络通过项目的知识图捕捉用户基于属性的偏好，最后，序列的偏好和属性偏好被结合起来作为最后用户偏好的表示。</p>
<p>Huang2019进一步包含多种形式的知识图到推荐模型中，这个方法可以捕捉用户动态的偏好。</p>
<p>Ma2019b提出的框架整合了知识图谱的规则归纳以及一个规则引导的神经推荐模型，一个模型基于的是从知识图中挖掘出来的规则（用于表示项目之间的关系），另一个模型用于推荐。</p>
<p>真实的知识图是很大的，计算开销很大，Xian2019提出一个强化学习的方法，用于路径查找，这样就避免了枚举所有用户-项目路径再比较相似性了。</p>
<h3 id="Rule-Mining-for-Explainable-Recommendation"><a href="#Rule-Mining-for-Explainable-Recommendation" class="headerlink" title="Rule Mining for Explainable Recommendation"></a>Rule Mining for Explainable Recommendation</h3><p>规则挖掘在可解释推荐上具有天然的优势，因为这些抽取出来的规则就可以作为解释的一部分</p>
<p>主要用于可解释推荐的规则挖掘是<strong>关联规则挖掘</strong>，Agrawal1993、1994是关于规则挖掘的文章</p>
<p>使用关联规则挖掘进行推荐的文章有：</p>
<ul>
<li>Mobasher2001：网页推荐</li>
<li>Cho2002：结合了决策树，进行网页商店推荐</li>
<li>Smyth2005：会话推荐任务</li>
<li>Sandvig2007：研究协同推荐的鲁棒性</li>
<li>Zhang2015a：对浏览器日志使用频率模式挖掘进行推荐</li>
<li>Amatriain2015：一篇关于将数据挖掘用于推荐系统的文章</li>
</ul>
<p>在可解释性推荐方面的关联规则方式的使用有一下文章：del </p>
<ul>
<li>Lin2000、2002：提出针对特定用户的关联规则，即个性化关联规则</li>
<li>Davidson2010：介绍了Youtube的视频推荐，方法大概是，对一段时间的观看数据进行挖掘，统计每对影片的相关程度，将用户最近看过的，或者喜欢的电影作为种子，将和该种子相关性高的电影推荐给用户，这种相关性就可以作为推荐的解释</li>
<li>Balog2019：一种基于集合的方法，解释是句子形式的</li>
</ul>
<h3 id="Model-Agnostic-and-Post-Hoc-Explainable-Recommendation"><a href="#Model-Agnostic-and-Post-Hoc-Explainable-Recommendation" class="headerlink" title="Model Agnostic and Post Hoc Explainable Recommendation"></a>Model Agnostic and Post Hoc Explainable Recommendation</h3><p>如果产生推荐的机制非常复杂，那么无法从如何产生推荐这个角度进行解释了，此时，可以将产生推荐的模块和产生解释的模块分开来，先产生推荐，再根据产生的推荐生成解释，这种方式被称为事后解释（Post Hoc）或者模型不相关方法。</p>
<p>常见的事后解释方式是使用一些统计信息进行解释，统计信息则是通过关联规则挖掘得到的，表现形式是将这些信息添加到事先定义好的句子模板中。</p>
<p>事后解释的相关论文有：</p>
<ul>
<li>Peake and Wang2018：将推荐模型视为一个黑箱，使用推荐模型的输入和输出抽取关联特征，通过这些关联特征进行解释</li>
<li>Singh and Anand2018：研究的是排名算法的事后解释</li>
<li>Ribeiro2016：其中心思想是使用简单的模型近似复杂的模型，他提出LIME，采用稀疏的线性模型来近似复杂的模型，线性模型可以向我们解释样本的哪个属性对于预测结果有重要作用</li>
<li>Singh and Anand2019：使用LIME对排名算法进行解释</li>
<li>McInerney2018：其提出bandit方法，该文章认为，用户对于解释的态度是动态的，对于不同的用户，给的解释不能相同，如何选择一个合适该用户的解释，是一个问题</li>
<li>Wang2018d：提出一个强化学习框架，用于为推荐产生句子级别的解释</li>
<li>Cheng2019a：提出FIA方法，使用因素分析（influence analysis）方法解释推荐，这是一种数学上的理解</li>
</ul>
<p>总的来说，事后的解释（post-hoc）的优点在于它可以适用很多推荐模型，因为它另外构造了一个解释模型，缺点就是解释的可信度有限。</p>
<h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h3><p>推荐系统的解释性主要是从两个方面入手，一个是推荐过程的可解释性，一个是推荐结果的可解释性，其代表了两种认知科学的观点，一种是通过逐步推理做出决定，一种是直觉的做出决定，再回头寻找理由。Lipton2018和Miller2019对这种认知科学进行了解释。</p>
<h2 id="Evaluation-of-Explainable-Recommendation"><a href="#Evaluation-of-Explainable-Recommendation" class="headerlink" title="Evaluation of Explainable Recommendation"></a>Evaluation of Explainable Recommendation</h2><p>我们所追求的理想的可解释推荐系统是，在推荐方面要超过非可解释推荐系统，同时在可解释性方面要更好。</p>
<p>为了进行比较，需要定义一系列的比较方法，在推荐方面的评价方式有：</p>
<ul>
<li>对于评分预测类型的推荐：平均绝对误差（MAE）、开方均方误差（RMSE）</li>
<li>对于top-n类型的推荐：精度、召回率、F-measure、NDCG、在线测量点击率或者转化率</li>
</ul>
<p>在可解释性比较方面：</p>
<p>有在线比较和离线比较方式，离线比较容易实现，在线比较不是必须</p>
<h3 id="User-Study"><a href="#User-Study" class="headerlink" title="User Study"></a>User Study</h3><p>用户调研主要指的使用众包网站，发布调查问卷，调查人们对于推荐解释的满意程度，并以此作为评价一个可解释推荐的标准。常用的众包网站有AMT、CrowdFlower。</p>
<h3 id="Online-Evaluation"><a href="#Online-Evaluation" class="headerlink" title="Online Evaluation"></a>Online Evaluation</h3><p>在线评价其实就是把模型放到实际的网站上，比如购物网站，通过分析用户的点击率（CTR）或者用户最终购买商品的比例（转化率），用于评价对于推荐的解释是不是有效的。这种方法和User Study都是在网上进行的，他们之间的不同是User Study中被调查的人是知道自己正在做一个推荐系统的调查，这样可能不能完全反应其真实状况，而在线评价是在用户未知的情况下进行的。</p>
<h3 id="Offline-Evaluation"><a href="#Offline-Evaluation" class="headerlink" title="Offline Evaluation"></a>Offline Evaluation</h3><p>离线的可解释推荐效果评价主要有两种方法，一种是推荐可以被解释模型解释的百分比，另一种是解释的质量。</p>
<ul>
<li>可以被解释模型解释的推荐占的百分比：MEP、MER、Fidelity</li>
<li>评价解释的质量：BLEU、ROUGE、Lin（这三个方法都是评价生成的解释和标的的解释是否相似的）； Gunning Fog Index 、Flesch Reading Ease 、Flesch Kincaid Grade Level 、 Automated Readability Index、 Smog Index （这些评价方式是评价解释的可读性的）</li>
</ul>
<h3 id="Qualitative-Evaluation-by-Case-Study"><a href="#Qualitative-Evaluation-by-Case-Study" class="headerlink" title="Qualitative Evaluation by Case Study"></a>Qualitative Evaluation by Case Study</h3><p>个案分析是通过分析某个用户和被推荐项目之间的相似性达到的，可以通过雷达图进行表示，在图上可以看到用户关注的东西和被推荐的东西之间的相似性。</p>
<h2 id="Explainable-Recommendation-in-Diﬀerent-Applications"><a href="#Explainable-Recommendation-in-Diﬀerent-Applications" class="headerlink" title="Explainable Recommendation in Diﬀerent Applications"></a>Explainable Recommendation in Diﬀerent Applications</h2><p>本节主要盘点可解释推荐在不同场景下的应用</p>
<h3 id="Explainable-E-commerce-Recommendation"><a href="#Explainable-E-commerce-Recommendation" class="headerlink" title="Explainable E-commerce Recommendation"></a>Explainable E-commerce Recommendation</h3><p>应用在电子商务推荐的论文包括：</p>
<ul>
<li>Zhang2014a：JD推荐</li>
<li>He2015：电子产品推荐</li>
<li>Chen2016：一种排名算法，用于跨类别推荐</li>
<li>Seo2017和Wu2019：Amazon推荐</li>
<li>Heckel2017：可扩展、解释的产品推荐</li>
<li>Chen2019b：可视化的解释，用于流行产品推荐</li>
<li>Hou2018：用于电子游戏产品推荐（Amazon）</li>
<li>Chen2018a：对评论进行神经注意力回归（Amazon）</li>
<li>Chen2018c：使用记忆里网络进行序列化推荐（Amazon）</li>
<li>Wang2018b：多任务学习（Amazon）</li>
<li>Ai2019：可解释的产品搜索</li>
</ul>
<p>如果把可解释的推荐意义提高，则可以认为是在实现社会责任推荐</p>
<h3 id="Explainable-Point-of-Interest-Recommendation"><a href="#Explainable-Point-of-Interest-Recommendation" class="headerlink" title="Explainable Point-of-Interest Recommendation"></a>Explainable Point-of-Interest Recommendation</h3><p>所谓POI推荐，一般都是位置推荐，比如酒店位置、餐厅位置、博物馆位置等等，一般使用的数据集是Yelp、TripAdvisor</p>
<p>关于POI推荐的论文主要有：</p>
<ul>
<li>Wu and Ester2015</li>
<li>Bauman2017</li>
<li>Seo2017</li>
<li>Zhao2015</li>
<li>Wang2018c</li>
<li>Baral2018</li>
</ul>
<h3 id="Explainable-Social-Recommendation"><a href="#Explainable-Social-Recommendation" class="headerlink" title="Explainable Social Recommendation"></a>Explainable Social Recommendation</h3><p>社交推荐一般包括朋友推荐、新闻推荐、音乐推荐、博客推荐、网页推荐、图片推荐，只要是社交环境中的推荐都算是推荐。</p>
<p>相关的论文主要有：</p>
<ul>
<li>Bountouridis2018：关于新闻可信度研究</li>
<li>Ren2017：社交推荐</li>
<li>Quijano2017：组推荐</li>
<li>Tsai2018：社交推荐</li>
</ul>
<h3 id="Explainable-Multimedia-Recommendation"><a href="#Explainable-Multimedia-Recommendation" class="headerlink" title="Explainable Multimedia Recommendation"></a>Explainable Multimedia Recommendation</h3><p>多媒体推荐的应用主要体现在书籍推荐、新闻推荐、音乐推荐、电影推荐、视频推荐，经常使用MovieLens数据集，相关论文主要有：</p>
<ul>
<li>Abdollahi and Nasraoui2016、2917：使用的是矩阵因式分解</li>
<li>Chang2016：使用众包生成自然语言解释</li>
<li>Lee2018：多个方面的解释电影推荐</li>
<li>Catherine2017：使用知识图谱进行电影推荐</li>
<li>Wang2018a：使用波纹网络在知识图谱上传递用户偏好，用于多媒体推荐</li>
<li>Zhao2019a：研究的是微软小冰的可解释歌曲推荐</li>
<li>Davidson2010：使用关联规则挖掘解释YouTube的视频推荐</li>
<li>Kraus2016：研究新闻推荐的可解释性</li>
</ul>
<h3 id="Other-Explainable-Recommendation-Applications"><a href="#Other-Explainable-Recommendation-Applications" class="headerlink" title="Other Explainable Recommendation Applications"></a>Other Explainable Recommendation Applications</h3><p>可解释推荐还能应用在其他的方面，比如学术推荐、引用推荐、法律推荐、医疗保健推荐等等。相关的论文包括：</p>
<ul>
<li>Gao2017：研究在线医疗保健论坛中的可解释文本分类</li>
<li>Liu2018：研究健康监测中的离群点可解释监测</li>
<li>Singh2019：可解释搜索</li>
<li>Zhao2019b：问答系统</li>
<li>Bountouridis2018：新闻可信度分析</li>
</ul>
<h3 id="Summary-1"><a href="#Summary-1" class="headerlink" title="Summary"></a>Summary</h3><p>并不是所有的推荐都需要或者说适合提供解释，比如，如果推荐的内容是time-critical（时序严格的），那么需要在尽快的时间内做出决定，而不是倾听解释来验证决定的正确性</p>
<h2 id="Open-Directions-and-New-Perspectives"><a href="#Open-Directions-and-New-Perspectives" class="headerlink" title="Open Directions and New Perspectives"></a>Open Directions and New Perspectives</h2><p>在这个部分主要说明目前可解释推荐的一些研究方向和新的研究角度。</p>
<h3 id="Explainable-Deep-Learning-for-Recommendation"><a href="#Explainable-Deep-Learning-for-Recommendation" class="headerlink" title="Explainable Deep Learning for Recommendation"></a>Explainable Deep Learning for Recommendation</h3><p>研究人员比较关注开发可解释的深度学习模型用于可解释的推荐，当前的方式主要是设计出能同时产生推荐和解释的深度模型。解释主要来源于注意力权重。在很多情况下，深度学习是一个黑箱主要原因是隐藏层没有拥有直观的含义。</p>
<ul>
<li>Koh2017：提出基于影响分析对深度神经网络进行分析</li>
<li>Pei2017：提出白盒测试机制用于帮助理解深度学习系统</li>
</ul>
<h3 id="Konwledge-enhanced-Explainable-Recommendation"><a href="#Konwledge-enhanced-Explainable-Recommendation" class="headerlink" title="Konwledge-enhanced Explainable Recommendation"></a>Konwledge-enhanced Explainable Recommendation</h3><p>如果推荐系统能知道关于推荐领域的特定知识，那么就可以产生更具有说服力的解释和推荐，比方说在电影推荐中，知道演员和导演的知识。随着知识图谱嵌入技术的发展，将图嵌入和推荐模型结合起来，这样做出的推荐就可以利用特定的领域知识了，同时，这样还可以构建对话式的推荐系统。</p>
<h3 id="Multi-Modality-and-Heterogenous-Information-Modeling"><a href="#Multi-Modality-and-Heterogenous-Information-Modeling" class="headerlink" title="Multi-Modality and Heterogenous Information Modeling"></a>Multi-Modality and Heterogenous Information Modeling</h3><p>在搜索和推荐中，常常使用的数据是多种形式，来源于多种信息源的，比如文档、图片、音频、视频等等，这类信息称为异质化信息，为了面对这些信息，需要研究跨领域信息的对齐和抽取。</p>
<h3 id="Context-aware-Explanations"><a href="#Context-aware-Explanations" class="headerlink" title="Context-aware Explanations"></a>Context-aware Explanations</h3><p>由于用户的偏好、项目的属性是动态变化的，会随着环境的改变而改变，因此，对用户的推荐以及推荐的解释也应该要动态变化，但是，当前的很多可解释推荐模型都是静态的，都是相对数据集来说的，而不是实际。</p>
<h3 id="Aggregation-of-Different-Explanations"><a href="#Aggregation-of-Different-Explanations" class="headerlink" title="Aggregation of Different Explanations"></a>Aggregation of Different Explanations</h3><p>为了不同的目的，通常需要产生不同的解释，那么，如何选择和组织这些解释，让它们形成一个逻辑统一的解释，是很总要的，也是一个研究的方向。</p>
<h3 id="Explainable-Recommendation-as-Reasoning"><a href="#Explainable-Recommendation-as-Reasoning" class="headerlink" title="Explainable Recommendation as Reasoning"></a>Explainable Recommendation as Reasoning</h3><p>推理过程透明的模型一般效果不太好，效果好的一般不透明，因此，如何将两者结合起来，将协同过滤变成协同推理，是解决这个矛盾的一种方式。</p>
<h3 id="NLP-and-Explainable-Recommendation"><a href="#NLP-and-Explainable-Recommendation" class="headerlink" title="NLP and Explainable Recommendation"></a>NLP and Explainable Recommendation</h3><p>比较自然的解释应该是自然语言的解释，而不是基于模板句子的解释，这种解释称为free-text解释。</p>
<p>对于NLP解释的一个简单想法就是训练一个语言生成模型，使用NLP生成解释仍然处于初级阶段，需要解决的问题有，如何去除评论中和解释无关的东西、如何个性化的生成解释、如何生成混合的解释（混合了图片等等的）</p>
<h3 id="Answering-the-Why-in-Conversations"><a href="#Answering-the-Why-in-Conversations" class="headerlink" title="Answering the Why in Conversations"></a>Answering the Why in Conversations</h3><p>推荐的解释按照给出的形式可以分为主动获得、被动获得，一般电子商务的商品推荐的解释都是被动获得的，因为它在给出推荐的时候顺便给出了解释，对于主动得到的解释，有一个例子，微软小冰的歌曲推荐，微软小冰会在你需要解释的时候给你解释。</p>
<h3 id="Evaluation-of-Explainable-Recommendations"><a href="#Evaluation-of-Explainable-Recommendations" class="headerlink" title="Evaluation of Explainable Recommendations"></a>Evaluation of Explainable Recommendations</h3><p>评价一个可解释推荐系统的解释性是一个难题，尤其是离线评价可解释性，而且，对于不同角度的可解释性的评价方式也是不一样的。</p>
<h3 id="User-Behavior-Perspectives"><a href="#User-Behavior-Perspectives" class="headerlink" title="User Behavior Perspectives"></a>User Behavior Perspectives</h3><p>推荐系统其实属于一种人机交互系统，因此，对于用户的行为进行分析，可以有助于评价一个系统的性能</p>
<h3 id="Explanation-for-Broader-Impects"><a href="#Explanation-for-Broader-Impects" class="headerlink" title="Explanation for Broader Impects"></a>Explanation for Broader Impects</h3><p>目前，解释一般用来说服用户相信一个推荐，但是，解释还有很多其他的影响，比如改善信任程度、有效性、多样性、满足感、公平性等等。</p>
<h3 id="Cognitive-Science-Foundations"><a href="#Cognitive-Science-Foundations" class="headerlink" title="Cognitive Science Foundations"></a>Cognitive Science Foundations</h3><p>关于可解释推荐或者可解释的AI，有两种研究哲学，一种是构建透明的模型，展示生成推荐的每个过程，另一种是先生成推荐，再寻求解释；这两种到低哪种是对的，是一个研究的方向。</p>
<h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>解释性的缺乏主要存在两个方面，一是推荐系统的输出结果对于用户来说解释性缺乏；二是推荐模型的机制对于系统设计者来说解释性缺乏。</p>
</div><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">YoYoghurt</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://yoursite.com/2020/07/13/Explainable-Recommendation%EF%BC%9A-A-Survey-and-New-Perspectives/">http://yoursite.com/2020/07/13/Explainable-Recommendation：-A-Survey-and-New-Perspectives/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://yoursite.com" target="_blank">YoYoghurt's Blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Explainable-Recommendation/">Explainable Recommendation</a><a class="post-meta__tags" href="/tags/Paper-Reading/">Paper_Reading</a></div><div class="post_share"><div class="social-share" data-image="https://cdn.jsdelivr.net/gh/Mr-Yellow/ImgHosting/Blog-Pic20200705174112.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css"/><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js"></script></div></div><nav class="pagination-post" id="pagination"><div class="next-post pull-full"><a href="/2020/07/01/construct-the-blog/"><img class="next-cover" data-src="https://cdn.jsdelivr.net/gh/Mr-Yellow/ImgHosting/Blog-Pic20200705181137.jpg" onerror="onerror=null;src='https://cdn.jsdelivr.net/gh/Mr-Yellow/ImgHosting/Blog-Pic20200705172813.jpg'"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Hexo搭建过程</div></div></a></div></nav><hr><div id="post-comment"><div class="comment_headling"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div><div id="gitalk-container"></div><script>var gitalk = new Gitalk({
  clientID: '33285ddcbc5e53521e96',
  clientSecret: '7a090b05f53496fb8ed8c5af29203a24717c046b',
  repo: 'GitalkRepo',
  owner: 'Mr-Yellow',
  admin: ['Mr-Yellow'],
  id: md5(decodeURI(location.pathname)),
  language: 'zh-CN',
  perPage: 10,
  distractionFreeMode: true,
  pagerDirection: 'last',
  createIssueManually: false,
  updateCountCallback: commentCount
})
gitalk.render('gitalk-container')

function commentCount(n){
  try {
    document.getElementsByClassName('gitalk-comment-count')[0].innerHTML= n
  } catch (e) {
    return false
  }
}</script></div></article></main><footer id="footer" data-type="color"><div id="footer-wrap"><div class="copyright">&copy;2020 By YoYoghurt</div><div class="framework-info"><span>驱动 </span><a href="https://hexo.io" target="_blank" rel="noopener"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 </span><a href="https://github.com/jerryc127/hexo-theme-butterfly" target="_blank" rel="noopener"><span>Butterfly</span></a></div><div class="footer_custom_text">Welcome to my blog !</div></div></footer></div><section class="rightside" id="rightside"><div id="rightside-config-hide"><button id="readmode" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="font_plus" title="放大字体"><i class="fas fa-plus"></i></button><button id="font_minus" title="缩小字体"><i class="fas fa-minus"></i></button><button class="translate_chn_to_cht" id="translateLink" title="简繁转换">繁</button><button id="darkmode" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button></div><div id="rightside-config-show"><button id="rightside_config" title="设置"><i class="fas fa-cog"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="scroll_to_comment fas fa-comments"></i></a><button class="close" id="mobile-toc-button" title="目录"><i class="fas fa-list-ul"></i></button><button id="chat_btn" title="rightside.chat_btn"><i class="fas fa-sms"></i></button><button id="go-up" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></section><div class="search-dialog" id="local-search"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"><div id="local-hits"></div><div id="local-stats"><div class="local-search-stats__hr" id="hr"><span>由</span> <a href="https://github.com/wzpan/hexo-generator-search" target="_blank" rel="noopener" style="color:#49B1F5;">hexo-generator-search</a>
 <span>提供支持</span></div></div></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div class="search-mask"></div><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script defer id="ribbon" src="/js/third-party/canvas-ribbon.js" size="150" alpha="0.6" zIndex="-1" mobile="false" data-click="true"></script><script id="canvas_nest" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="false" src="/js/third-party/canvas-nest.js"></script><script src="/js/third-party/activate-power-mode.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = true;
document.body.addEventListener('input', POWERMODE);
</script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module" defer></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js" async></script><script src="/js/search/local-search.js"></script><script>var endLoading = function () {
  document.body.style.overflow = 'auto';
  document.getElementById('loading-box').classList.add("loaded")
}
window.addEventListener('load',endLoading)</script><script>(function(d, w, c) {
    w.ChatraID = 'uy5SRZRkdiYZToFAf';
    var s = d.createElement('script');
    w[c] = w[c] || function() {
        (w[c].q = w[c].q || []).push(arguments);
    };
    s.async = true;
    s.src = 'https://call.chatra.io/chatra.js';
    if (d.head) d.head.appendChild(s);
})(document, window, 'Chatra');

if (true) {
  var chatBtn = document.getElementById("chat_btn")
    chatBtn.addEventListener("click", function(){
      Chatra('openChat')
    });
} else {
  if (true) {
    function chatBtnHide () {
      Chatra('hide')
    }
    function chatBtnShow () {
      Chatra('show')
    }
  }
}</script></body></html>